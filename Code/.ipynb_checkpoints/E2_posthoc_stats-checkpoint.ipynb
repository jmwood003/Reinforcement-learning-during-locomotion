{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73cc8f48-4235-48e9-a8cc-f0c0283bcf1e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b5d56-11e1-44c4-b7b8-87220e0d97b7",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ef38d8-3dd6-40e5-acb1-c2761971c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v4.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bayes_toolbox.glm as bst\n",
    "import os\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import theano.tensor as tt\n",
    "from theano.compile.ops import as_op\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")\n",
    "\n",
    "# Set colors for plotting\n",
    "rpe_color = '#c51b7d'\n",
    "te_color = '#276419'\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "#Pymc sampling\n",
    "seed_num = 100\n",
    "n_samples = 10000\n",
    "\n",
    "grp_names = ['RPE', 'TE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981ca44-1da7-4a8e-9fce-b42f87afa4b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284a143b-d207-470c-b75e-abb7e317ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_mixed_model_anova(between_subj_var, within_subj_var, subj_id, y, n_draws=1000, rnd_seed=100):\n",
    "    \"\"\"Performs Bayesian analogue of mixed model (split-plot) ANOVA.\n",
    "    \n",
    "    Models instance of outcome resulting from both between- and within-subjects\n",
    "    factors. Outcome is measured several times from each observational unit (i.e.,\n",
    "    repeated measures). \n",
    "    \n",
    "    Args:\n",
    "        between_subj_var: The between-subjects variable.\n",
    "        withing_subj_var: The within-subjects variable.\n",
    "        subj_id: The subj ID variable. \n",
    "        y: The outcome variable. \n",
    "    \n",
    "    Returns: \n",
    "        PyMC Model and InferenceData objects. \n",
    "    \"\"\"\n",
    "    # Statistical model: Split-plot design after Kruschke Ch. 20\n",
    "    # Between-subjects factor (i.e., group)\n",
    "    x_between, levels_x_between, num_levels_x_between = bst.parse_categorical(between_subj_var)\n",
    "  \n",
    "    # Within-subjects factor (i.e., target set)\n",
    "    x_within, levels_x_within, num_levels_x_within = bst.parse_categorical(within_subj_var)\n",
    "\n",
    "    # Individual subjects\n",
    "    x_subj, levels_x_subj, num_levels_x_subj = bst.parse_categorical(subj_id)\n",
    "\n",
    "    # Dependent variable \n",
    "    mu_y = y.mean()\n",
    "    sigma_y = y.std()\n",
    "\n",
    "    a_shape, a_rate = bst.gamma_shape_rate_from_mode_sd(sigma_y / 2 , 2 * sigma_y)\n",
    "\n",
    "    with pm.Model(coords={\n",
    "        \"between_subj\": levels_x_between, \n",
    "        \"within_subj\": levels_x_within,\n",
    "        \"subj\": levels_x_subj}\n",
    "        ) as model:\n",
    "\n",
    "        # Baseline value\n",
    "        a0 = pm.Normal('a0', mu=mu_y, sigma=sigma_y * 5)\n",
    "\n",
    "        # Deflection from baseline for between subjects factor\n",
    "        sigma_B = pm.Gamma('sigma_B', a_shape, a_rate)\n",
    "        aB = pm.Normal('aB', mu=0.0, sigma=sigma_B, dims=\"between_subj\")\n",
    "\n",
    "        # Deflection from baseline for within subjects factor\n",
    "        sigma_W = pm.Gamma('sigma_W', a_shape, a_rate)\n",
    "        aW = pm.Normal('aW', mu=0.0, sigma=sigma_W, dims=\"within_subj\")\n",
    "\n",
    "        # Deflection from baseline for combination of between and within subjects factors\n",
    "        sigma_BxW = pm.Gamma('sigma_BxW', a_shape, a_rate)\n",
    "        aBxW = pm.Normal('aBxW', mu=0.0, sigma=sigma_BxW, dims=(\"between_subj\", \"within_subj\"))\n",
    "\n",
    "        # Deflection from baseline for individual subjects\n",
    "        sigma_S = pm.Gamma('sigma_S', a_shape, a_rate)\n",
    "        aS = pm.Normal('aS', mu=0.0, sigma=sigma_S, dims=\"subj\")\n",
    "\n",
    "        mu = a0 + aB[x_between] + aW[x_within] + aBxW[x_between, x_within] + aS[x_subj] \n",
    "        \n",
    "        #Assumes same variance\n",
    "        sigma = pm.Uniform('sigma', lower=sigma_y / 100, upper=sigma_y * 10)\n",
    "\n",
    "        # Define likelihood \n",
    "        likelihood = pm.Normal('likelihood', mu=mu, sigma=sigma, observed=y)\n",
    "        \n",
    "        # Sample from the posterior\n",
    "        idata = pm.sample(draws=n_draws, tune=2000, target_accept=0.95, random_seed=rnd_seed)\n",
    "    \n",
    "    return model, idata\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def tdist_bayesian_mixed_model_anova(between_subj_var, within_subj_var, subj_id, y, n_draws=1000, rnd_seed=100):\n",
    "    \"\"\"Performs Bayesian analogue of mixed model (split-plot) ANOVA.\n",
    "    \n",
    "    Models instance of outcome resulting from both between- and within-subjects\n",
    "    factors. Outcome is measured several times from each observational unit (i.e.,\n",
    "    repeated measures). \n",
    "    \n",
    "    Args:\n",
    "        between_subj_var: The between-subjects variable.\n",
    "        withing_subj_var: The within-subjects variable.\n",
    "        subj_id: The subj ID variable. \n",
    "        y: The outcome variable. \n",
    "    \n",
    "    Returns: \n",
    "        PyMC Model and InferenceData objects. \n",
    "    \"\"\"\n",
    "    # Statistical model: Split-plot design after Kruschke Ch. 20\n",
    "    # Between-subjects factor (i.e., group)\n",
    "    x_between, levels_x_between, num_levels_x_between = bst.parse_categorical(between_subj_var)\n",
    "  \n",
    "    # Within-subjects factor (i.e., target set)\n",
    "    x_within, levels_x_within, num_levels_x_within = bst.parse_categorical(within_subj_var)\n",
    "\n",
    "    # Individual subjects\n",
    "    x_subj, levels_x_subj, num_levels_x_subj = bst.parse_categorical(subj_id)\n",
    "\n",
    "    # Dependent variable \n",
    "    mu_y = y.mean()\n",
    "    sigma_y = y.std()\n",
    "\n",
    "    a_shape, a_rate = bst.gamma_shape_rate_from_mode_sd(sigma_y / 2 , 2 * sigma_y)\n",
    "\n",
    "    with pm.Model(coords={\n",
    "        \"between_subj\": levels_x_between, \n",
    "        \"within_subj\": levels_x_within,\n",
    "        \"subj\": levels_x_subj}\n",
    "        ) as model:\n",
    "\n",
    "        # Baseline value\n",
    "        a0 = pm.Normal('a0', mu=mu_y, sigma=sigma_y * 5)\n",
    "\n",
    "        # Deflection from baseline for between subjects factor\n",
    "        sigma_B = pm.Gamma('sigma_B', a_shape, a_rate)\n",
    "        aB = pm.Normal('aB', mu=0.0, sigma=sigma_B, dims=\"between_subj\")\n",
    "\n",
    "        # Deflection from baseline for within subjects factor\n",
    "        sigma_W = pm.Gamma('sigma_W', a_shape, a_rate)\n",
    "        aW = pm.Normal('aW', mu=0.0, sigma=sigma_W, dims=\"within_subj\")\n",
    "\n",
    "        # Deflection from baseline for combination of between and within subjects factors\n",
    "        sigma_BxW = pm.Gamma('sigma_BxW', a_shape, a_rate)\n",
    "        aBxW = pm.Normal('aBxW', mu=0.0, sigma=sigma_BxW, dims=(\"between_subj\", \"within_subj\"))\n",
    "\n",
    "        # Deflection from baseline for individual subjects\n",
    "        sigma_S = pm.Gamma('sigma_S', a_shape, a_rate)\n",
    "        aS = pm.Normal('aS', mu=0.0, sigma=sigma_S, dims=\"subj\")\n",
    "\n",
    "        mu = a0 + aB[x_between] + aW[x_within] + aBxW[x_between, x_within] + aS[x_subj] \n",
    "        \n",
    "        #Assumes same variance\n",
    "        sigma = pm.Uniform('sigma', lower=sigma_y / 100, upper=sigma_y * 10)\n",
    "\n",
    "        #Prior on nu parameter\n",
    "        nu_minus1 = pm.Exponential('nu_minus1', 1 / 29)\n",
    "        nu = pm.Deterministic('nu', nu_minus1 + 1)     \n",
    "        \n",
    "        # Define likelihood \n",
    "        likelihood = pm.StudentT('likelihood', nu=nu, mu=mu, sigma=sigma, observed=y)\n",
    "        \n",
    "        # Sample from the posterior\n",
    "        idata = pm.sample(draws=n_draws, tune=2000, target_accept=0.95, random_seed=rnd_seed)\n",
    "    \n",
    "    return model, idata\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def robust_bayesian_mixed_model_anova(between_subj_var, within_subj_var, subj_id, y, n_draws=1000, rnd_seed=100):\n",
    "    \"\"\"Performs Bayesian analogue of mixed model (split-plot) ANOVA.\n",
    "    \n",
    "    Models instance of outcome resulting from both between- and within-subjects\n",
    "    factors. Outcome is measured several times from each observational unit (i.e.,\n",
    "    repeated measures). \n",
    "    \n",
    "    Args:\n",
    "        between_subj_var: The between-subjects variable.\n",
    "        withing_subj_var: The within-subjects variable.\n",
    "        subj_id: The subj ID variable. \n",
    "        y: The outcome variable. \n",
    "    \n",
    "    Returns: \n",
    "        PyMC Model and InferenceData objects. \n",
    "    \"\"\"\n",
    "    # Statistical model: Split-plot design after Kruschke Ch. 20\n",
    "    # Between-subjects factor (i.e., group)\n",
    "    x_between, levels_x_between, num_levels_x_between = bst.parse_categorical(between_subj_var)\n",
    "  \n",
    "    # Within-subjects factor (i.e., target set)\n",
    "    x_within, levels_x_within, num_levels_x_within = bst.parse_categorical(within_subj_var)\n",
    "\n",
    "    # Individual subjects\n",
    "    x_subj, levels_x_subj, num_levels_x_subj = bst.parse_categorical(subj_id)\n",
    "\n",
    "    # Dependent variable \n",
    "    mu_y = y.mean()\n",
    "    sigma_y = y.std()\n",
    "\n",
    "    a_shape, a_rate = bst.gamma_shape_rate_from_mode_sd(sigma_y / 2 , 2 * sigma_y)\n",
    "\n",
    "    with pm.Model(coords={\n",
    "        \"between_subj\": levels_x_between, \n",
    "        \"within_subj\": levels_x_within,\n",
    "        \"subj\": levels_x_subj}\n",
    "        ) as model:\n",
    "\n",
    "        # Baseline value\n",
    "        a0 = pm.Normal('a0', mu=mu_y, sigma=sigma_y * 5)\n",
    "\n",
    "        # Deflection from baseline for between subjects factor\n",
    "        sigma_B = pm.Gamma('sigma_B', a_shape, a_rate)\n",
    "        aB = pm.Normal('aB', mu=0.0, sigma=sigma_B, dims=\"between_subj\")\n",
    "\n",
    "        # Deflection from baseline for within subjects factor\n",
    "        sigma_W = pm.Gamma('sigma_W', a_shape, a_rate)\n",
    "        aW = pm.Normal('aW', mu=0.0, sigma=sigma_W, dims=\"within_subj\")\n",
    "\n",
    "        # Deflection from baseline for combination of between and within subjects factors\n",
    "        sigma_BxW = pm.Gamma('sigma_BxW', a_shape, a_rate)\n",
    "        aBxW = pm.Normal('aBxW', mu=0.0, sigma=sigma_BxW, dims=(\"between_subj\", \"within_subj\"))\n",
    "\n",
    "        # Deflection from baseline for individual subjects\n",
    "        sigma_S = pm.Gamma('sigma_S', a_shape, a_rate)\n",
    "        aS = pm.Normal('aS', mu=0.0, sigma=sigma_S, dims=\"subj\")\n",
    "\n",
    "        mu = a0 + aB[x_between] + aW[x_within] + aBxW[x_between, x_within] + aS[x_subj] \n",
    "        \n",
    "        #Assumes different variances \n",
    "        sigma = pm.Uniform('sigma', lower=sigma_y / 100, upper=sigma_y * 10, dims=(\"between_subj\", \"within_subj\"))\n",
    "\n",
    "        #Prior on nu parameter\n",
    "        nu_minus1 = pm.Exponential('nu_minus1', 1 / 29)\n",
    "        nu = pm.Deterministic('nu', nu_minus1 + 1)     \n",
    "        \n",
    "        # Define likelihood \n",
    "        likelihood = pm.StudentT('likelihood', nu=nu, mu=mu, sigma=sigma[x_between, x_within], observed=y)\n",
    "        \n",
    "        # Sample from the posterior\n",
    "        idata = pm.sample(draws=n_draws, tune=2000, target_accept=0.95, random_seed=rnd_seed)\n",
    "    \n",
    "    return model, idata\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def BEST(y, group, n_draws=1000, rnd_seed=100):\n",
    "    \"\"\"Implementation of John Kruschke's BEST test.\n",
    "    \n",
    "    Estimates parameters related to outcomes of two groups. See:\n",
    "        https://jkkweb.sitehost.iu.edu/articles/Kruschke2013JEPG.pdf\n",
    "        for more details. \n",
    "    \n",
    "    Args:\n",
    "        y (ndarray/Series): The metric outcome variable.\n",
    "        group: The grouping variable providing that indexes into y.\n",
    "        n_draws: Number of random samples to draw from the posterior.\n",
    "    \n",
    "    Returns: \n",
    "        PyMC Model and InferenceData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert grouping variable to categorical dtype if it is not already\n",
    "    if pd.api.types.is_categorical_dtype(group):\n",
    "        pass\n",
    "    else:\n",
    "        group = group.astype('category')\n",
    "    group_idx = group.cat.codes.values\n",
    "        \n",
    "    # Extract group levels and make sure there are only two\n",
    "    level = group.cat.categories\n",
    "    assert len(level) == 2, f\"Expected two groups but got {len(level)}.\"\n",
    "    \n",
    "    # Calculate pooled empirical mean and SD of data to scale hyperparameters\n",
    "    mu_y = y.mean()\n",
    "    sigma_y = y.std()\n",
    "                                                                     \n",
    "    with pm.Model() as model:\n",
    "        # Define priors. Arbitrarily set hyperparameters to the pooled \n",
    "        # empirical mean of data and twice pooled empirical SD, which \n",
    "        # applies very diffuse and unbiased info to these quantities. \n",
    "        group_mean = pm.Normal(\"group_mean\", mu=mu_y, sigma=sigma_y * 2, shape=len(level))\n",
    "        group_std = pm.Uniform(\"group_std\", lower=sigma_y / 10, upper=sigma_y * 10, shape=len(level))\n",
    "        \n",
    "        # See Kruschke Ch 16.2.1 for in-depth rationale for prior on nu. The addition of 1 is to shift the\n",
    "        # distribution so that the range of possible values of nu are 1 to infinity (with mean of 30).\n",
    "        nu_minus_one = pm.Exponential(\"nu_minus_one\", 1 / 29)\n",
    "        nu = pm.Deterministic(\"nu\", nu_minus_one + 1)\n",
    "        nu_log10 = pm.Deterministic(\"nu_log10\", np.log10(nu))\n",
    "        \n",
    "        # Define likelihood\n",
    "        likelihood = pm.StudentT(\"likelihood\", nu=nu, mu=group_mean[group_idx], sigma=group_std[group_idx], observed=y)\n",
    "        \n",
    "        # Contrasts of interest\n",
    "        diff_of_means = pm.Deterministic(\"difference of means\", group_mean[0] - group_mean[1])\n",
    "        diff_of_stds = pm.Deterministic(\"difference of stds\", group_std[0] - group_std[1])\n",
    "        effect_size = pm.Deterministic(\n",
    "            \"effect size\", diff_of_means / np.sqrt((group_std[0]**2 + group_std[1]**2) / 2)\n",
    "        )\n",
    "        \n",
    "        # Sample from posterior\n",
    "        idata = pm.sample(draws=n_draws, tune=2000, random_seed=rnd_seed)\n",
    "        \n",
    "    return model, idata\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_post_predictive_ttest(data, group, post, n_samps=20):\n",
    "    \n",
    "    grp_names = pd.unique(group)\n",
    "    var_name = data.name\n",
    "    # Set colors for plotting\n",
    "\n",
    "    grp_colors = ['#c51b7d', '#276419']\n",
    "    \n",
    "    x = np.linspace(np.min(post.group_mean)-np.max(post.group_std),np.max(post.group_mean)+np.max(post.group_std))\n",
    "    rand_idx = np.random.choice(len(post.group_mean[0,:]), n_samps)\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,3))\n",
    "    ax[0].hist(data[group==grp_names[0]], bins=10, density=True, alpha=0.5, color=grp_colors[0])\n",
    "    for i in rand_idx:\n",
    "        y = t.pdf(x, df=post.nu[i], loc=post.group_mean[0,i], scale=post.group_std[0,i])\n",
    "        ax[0].plot(x, y, c=grp_colors[0], alpha=0.2)\n",
    "    ax[0].set(title=grp_names[0]+' group', ylabel='probability', xlabel=var_name)\n",
    "\n",
    "    ax[1].hist(data[group==grp_names[1]],bins=10, density=True, alpha=0.5, color=grp_colors[1])\n",
    "    for i in rand_idx:\n",
    "        y = t.pdf(x, df=post.nu[i], loc=post.group_mean[1,i], scale=post.group_std[1,i])\n",
    "        ax[1].plot(x, y, c=grp_colors[1], alpha=0.2)\n",
    "    ax[1].set(title=grp_names[1]+' group', xlabel=var_name)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_post_simple_comparison(idata, grp_names, round_to):\n",
    "\n",
    "    az.plot_posterior(\n",
    "        idata,\n",
    "        var_names=[\"difference of means\", \"difference of stds\", \"effect size\"],\n",
    "        ref_val=0,\n",
    "        color=\"#87ceeb\",\n",
    "        kind=\"hist\",\n",
    "        round_to=round_to,\n",
    "        bins=50,\n",
    "        hdi_prob=0.95,\n",
    "    );\n",
    "    \n",
    "    summary = az.summary(idata,hdi_prob=0.95)\n",
    "\n",
    "    print(grp_names[0], 'mean =', round(summary['mean'][0],round_to), '[', round(summary['hdi_2.5%'][0],round_to), round(summary['hdi_97.5%'][0],round_to), ']')\n",
    "    print(grp_names[1], 'mean =', round(summary['mean'][1],round_to), '[', round(summary['hdi_2.5%'][1],round_to), round(summary['hdi_97.5%'][1],round_to), ']')\n",
    "    print('Difference of means =', round(summary['mean'][7],round_to), '[', round(summary['hdi_2.5%'][7],round_to), round(summary['hdi_97.5%'][7],round_to), ']')\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_mustache_norm(mu, sigma, plot_pos, width, color, ax=None):\n",
    "    for m, s in zip(mu, sigma):\n",
    "\n",
    "        rv = norm(loc=m, scale=s)\n",
    "        yrange = np.linspace(rv.ppf(0.01), rv.ppf(0.99), 100)\n",
    "        xrange = rv.pdf(yrange)\n",
    "        xrange_scaled = xrange*(width/xrange.max())\n",
    "        ax.plot(-xrange_scaled+plot_pos, yrange, color=color, alpha=.2)\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_mustache_tdist(mu, sigma, nu, plot_pos, width, color, ax=None):\n",
    "    for m, s, n in zip(mu, sigma, nu):\n",
    "\n",
    "        rv = t(df=n, loc=m, scale=s)\n",
    "        yrange = np.linspace(rv.ppf(0.01), rv.ppf(0.99), 100)\n",
    "        xrange = rv.pdf(yrange)\n",
    "        xrange_scaled = xrange*(width/xrange.max())\n",
    "        ax.plot(-xrange_scaled+plot_pos, yrange, color=color, alpha=.2)\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_posterior_predictive_anova_robust(between_subj, within_subj, y, post, n_mustaches):\n",
    "            \n",
    "    #Index group names\n",
    "    bs_names = pd.unique(between_subj)\n",
    "    ws_names = pd.unique(within_subj)\n",
    "    \n",
    "    #For indexing posterior\n",
    "    burn_in = post.tuning_steps\n",
    "    all_post_idx = np.arange(len(post.sample))\n",
    "    post_idx = np.random.randint(burn_in+1, all_post_idx[-1], n_mustaches)\n",
    "    \n",
    "    #Plot prep\n",
    "    group_colors = ['#c51b7d', '#276419']\n",
    "    x_offset = [-0.15, 0.15]\n",
    "    \n",
    "    #Initilize plot\n",
    "    fig, ax = plt.subplots(figsize=(10,5),tight_layout=True)\n",
    "    ax.plot(np.arange(0,len(ws_names)+2), np.zeros(len(ws_names)+2), 'k')\n",
    "    \n",
    "    for ws_idx, ws in enumerate(ws_names):\n",
    "        for bs_idx, bs in enumerate(bs_names):\n",
    "            #Index and plot emperical data\n",
    "            y_emp = y[within_subj==ws][between_subj==bs]\n",
    "            x = norm.rvs(1+ws_idx+x_offset[bs_idx],0.005,len(y_emp))\n",
    "            ax.plot(x, y_emp, 'o', c=group_colors[bs_idx], mec='w', alpha=0.5)\n",
    "            \n",
    "            #Index and plot posterior data\n",
    "            plot_mustache_tdist(mu=post.b0.values[post_idx]+\n",
    "                          post.bB.sel(between_subj=bs).values[post_idx]+\n",
    "                          post.bW.sel(within_subj=ws).values[post_idx]+\n",
    "                          post.bBxW.sel(between_subj=bs,within_subj=ws).values[post_idx], \n",
    "                          sigma=post.sigma.sel(between_subj=bs,within_subj=ws).values[post_idx], \n",
    "                          nu=post.nu.values[post_idx], \n",
    "                          plot_pos=0.95+ws_idx+x_offset[bs_idx], \n",
    "                          width=0.15, \n",
    "                          color=group_colors[bs_idx], ax=ax)\n",
    "            \n",
    "    ax.set(xlim=(0.5, len(ws_names)+0.5), \n",
    "           xticks=np.arange(1,len(ws_names)+1), \n",
    "           xticklabels=ws_names, \n",
    "           ylabel=y.name, \n",
    "           title='Posterior Predictive Check (' + y.name + ')'\n",
    "          )\n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_posterior_predictive_anova_tdist(between_subj, within_subj, y, post, n_mustaches):\n",
    "            \n",
    "    #Index group names\n",
    "    bs_names = pd.unique(between_subj)\n",
    "    ws_names = pd.unique(within_subj)\n",
    "    \n",
    "    #For indexing posterior\n",
    "    burn_in = post.tuning_steps\n",
    "    all_post_idx = np.arange(len(post.sample))\n",
    "    post_idx = np.random.randint(burn_in+1, all_post_idx[-1], n_mustaches)\n",
    "    \n",
    "    #Plot prep\n",
    "    group_colors = ['#c51b7d', '#276419']\n",
    "    x_offset = [-0.15, 0.15]\n",
    "    \n",
    "    #Initilize plot\n",
    "    fig, ax = plt.subplots(figsize=(10,5),tight_layout=True)\n",
    "    ax.plot(np.arange(0,len(ws_names)+2), np.zeros(len(ws_names)+2), 'k')\n",
    "    \n",
    "    for ws_idx, ws in enumerate(ws_names):\n",
    "        for bs_idx, bs in enumerate(bs_names):\n",
    "            #Index and plot emperical data\n",
    "            y_emp = y[within_subj==ws][between_subj==bs]\n",
    "            x = norm.rvs(1+ws_idx+x_offset[bs_idx],0.005,len(y_emp))\n",
    "            ax.plot(x, y_emp, 'o', c=group_colors[bs_idx], mec='w', alpha=0.5)\n",
    "            \n",
    "            #Index and plot posterior data\n",
    "            plot_mustache_tdist(mu=post.b0.values[post_idx]+\n",
    "                          post.bB.sel(between_subj=bs).values[post_idx]+\n",
    "                          post.bW.sel(within_subj=ws).values[post_idx]+\n",
    "                          post.bBxW.sel(between_subj=bs,within_subj=ws).values[post_idx], \n",
    "                          sigma=post.sigma.values[post_idx], \n",
    "                          nu=post.nu.values[post_idx], \n",
    "                          plot_pos=0.95+ws_idx+x_offset[bs_idx], \n",
    "                          width=0.15, \n",
    "                          color=group_colors[bs_idx], ax=ax)\n",
    "            \n",
    "    ax.set(xlim=(0.5, len(ws_names)+0.5), \n",
    "           xticks=np.arange(1,len(ws_names)+1), \n",
    "           xticklabels=ws_names, \n",
    "           ylabel=y.name, \n",
    "           title='Posterior Predictive Check (' + y.name + ')'\n",
    "          )\n",
    "    plt.show()\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_posterior_predictive_anova_norm(between_subj, within_subj, y, post, n_mustaches):\n",
    "            \n",
    "    #Index group names\n",
    "    bs_names = pd.unique(between_subj)\n",
    "    ws_names = pd.unique(within_subj)\n",
    "    \n",
    "    #For indexing posterior\n",
    "    burn_in = post.tuning_steps\n",
    "    all_post_idx = np.arange(len(post.sample))\n",
    "    post_idx = np.random.randint(burn_in+1, all_post_idx[-1], n_mustaches)\n",
    "    \n",
    "    #Plot prep\n",
    "    group_colors = ['#c51b7d', '#276419']\n",
    "    x_offset = [-0.15, 0.15]\n",
    "    \n",
    "    #Initilize plot\n",
    "    fig, ax = plt.subplots(figsize=(10,5),tight_layout=True)\n",
    "    ax.plot(np.arange(0,len(ws_names)+2), np.zeros(len(ws_names)+2), 'k')\n",
    "    \n",
    "    for ws_idx, ws in enumerate(ws_names):\n",
    "        for bs_idx, bs in enumerate(bs_names):\n",
    "            #Index and plot emperical data\n",
    "            y_emp = y[within_subj==ws][between_subj==bs]\n",
    "            x = norm.rvs(1+ws_idx+x_offset[bs_idx],0.005,len(y_emp))\n",
    "            ax.plot(x, y_emp, 'o', c=group_colors[bs_idx], mec='w', alpha=0.5)\n",
    "            \n",
    "            #Index and plot posterior data\n",
    "            plot_mustache_norm(mu=post.b0.values[post_idx]+\n",
    "                          post.bB.sel(between_subj=bs).values[post_idx]+\n",
    "                          post.bW.sel(within_subj=ws).values[post_idx]+\n",
    "                          post.bBxW.sel(between_subj=bs,within_subj=ws).values[post_idx], \n",
    "                          sigma=post.sigma.values[post_idx], \n",
    "                          plot_pos=0.95+ws_idx+x_offset[bs_idx], \n",
    "                          width=0.15, \n",
    "                          color=group_colors[bs_idx], ax=ax)\n",
    "            \n",
    "    ax.set(xlim=(0.5, len(ws_names)+0.5), \n",
    "           xticks=np.arange(1,len(ws_names)+1), \n",
    "           xticklabels=ws_names, \n",
    "           ylabel=y.name, \n",
    "           title='Posterior Predictive Check (' + y.name + ')'\n",
    "          )\n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_between_contrasts(post, between_subj, within_subj, round_to):\n",
    "\n",
    "    #Index the between and within subject names\n",
    "    bs_names = pd.unique(between_subj)\n",
    "    ws_names = pd.unique(within_subj)\n",
    "    \n",
    "    print('Interactions:')\n",
    "    \n",
    "    #Index the interaction contrasts\n",
    "    contrast_dict = {}\n",
    "    for ws_idx, ws in enumerate(ws_names):\n",
    "        single_contrast = []\n",
    "        for bs_idx, bs in enumerate(bs_names):\n",
    "            \n",
    "            post_indiv = post.b0 + post.bB.sel(between_subj=bs) + post.bW.sel(within_subj=ws) + post.bBxW.sel(between_subj=bs,within_subj=ws)\n",
    "            post_hdi = az.hdi(post_indiv.values, hdi_prob=0.95)\n",
    "            print('Posterior for', bs, ws, '=', np.round(np.mean(post_indiv.values),round_to), np.round(post_hdi,round_to))\n",
    "         \n",
    "            single_contrast.append(post_indiv)\n",
    "\n",
    "        contrast_str = bs_names[0] + ' vs ' + bs_names[1] + ' @ ' + ws\n",
    "        contrast = single_contrast[0] - single_contrast[1]        \n",
    "        contrast_hdi = az.hdi(contrast.values, hdi_prob=0.95)\n",
    "        \n",
    "        print(contrast_str, '=', np.round(np.mean(contrast.values),round_to), np.round(contrast_hdi,round_to))\n",
    "        print(' ')\n",
    "        \n",
    "        contrast_dict[contrast_str] = contrast\n",
    "    az.plot_posterior(contrast_dict, \n",
    "                      kind=\"hist\",\n",
    "                      combine_dims={\"sample\"},\n",
    "                      bins=50,\n",
    "                      point_estimate=\"mean\", \n",
    "                      ref_val=0,\n",
    "                      round_to=round_to,\n",
    "                      hdi_prob=0.95);\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_within_contrasts(post, round_to, between_factor):\n",
    "\n",
    "    #Index the between and within subject names\n",
    "    ws_names = post.within_subj.values\n",
    "    \n",
    "    print('Within subject contrasts:')\n",
    "    \n",
    "    if len(ws_names)==2:\n",
    "        comp_list = np.array([np.arange(2)])\n",
    "    elif len(ws_names)==3:\n",
    "        comp_list = np.array([[0,1], [0,2], [1,2]])\n",
    "    elif len(ws_names)==4:\n",
    "        comp_list = np.array([[0,1], [0,2], [0,3], [1,2], [1,3], [2,3]])\n",
    "\n",
    "    contrast_dict = {}\n",
    "    for c1, c2 in comp_list:\n",
    "\n",
    "        post_t1 = post.b0 + post.bB.sel(between_subj=between_factor) + post.bW.sel(within_subj=ws_names[c1]) + post.bBxW.sel(between_subj=between_factor,within_subj=ws_names[c1])\n",
    "        post_t2 = post.b0 + post.bB.sel(between_subj=between_factor) + post.bW.sel(within_subj=ws_names[c2]) + post.bBxW.sel(between_subj=between_factor,within_subj=ws_names[c2])\n",
    "\n",
    "        contrast_str = between_factor + ' ' + ws_names[c1] + ' vs ' + between_factor + ' ' + ws_names[c2]\n",
    "        contrast = post_t1 - post_t2\n",
    "        contrast_hdi = az.hdi(contrast.values, hdi_prob=0.95)\n",
    "\n",
    "        print(contrast_str, '=', np.round(np.mean(contrast.values),round_to), np.round(contrast_hdi,round_to))\n",
    "\n",
    "        #Append\n",
    "        contrast_dict[contrast_str] = contrast\n",
    "\n",
    "    az.plot_posterior(contrast_dict, \n",
    "                      kind=\"hist\",\n",
    "                      combine_dims={\"sample\"},\n",
    "                      bins=50,\n",
    "                      point_estimate=\"mean\", \n",
    "                      ref_val=0,\n",
    "                      round_to=round_to,\n",
    "                      hdi_prob=0.95);\n",
    "    \n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_main_effect_between(post, round_to):\n",
    "    \n",
    "    #Index the between names\n",
    "    bs_names = post.between_subj.values\n",
    "        \n",
    "    print('Between subject main effects:')\n",
    "    bs_contrast = post.bB.sel(between_subj=bs_names[0]) - post.bB.sel(between_subj=bs_names[1]) \n",
    "    bs_hdi = az.hdi(bs_contrast.values, hdi_prob=0.95)\n",
    "    print(bs_names[0], 'vs', bs_names[1], '=', np.round(np.mean(bs_contrast.values),round_to), np.round(bs_hdi,round_to))\n",
    "\n",
    "    az.plot_posterior(bs_contrast, \n",
    "                      kind=\"hist\",\n",
    "                      combine_dims={\"sample\"},\n",
    "                      bins=50,\n",
    "                      point_estimate=\"mean\", \n",
    "                      ref_val=0,\n",
    "                      round_to=round_to,\n",
    "                      hdi_prob=0.95);\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_main_effect_within(post, round_to):\n",
    "    \n",
    "    #Index the between and within subject names\n",
    "    ws_names = post.within_subj.values\n",
    "        \n",
    "    print('Within subject main effects:')\n",
    "    if len(ws_names)==2:\n",
    "        comp_list = np.array([np.arange(2)])\n",
    "    elif len(ws_names)==3:\n",
    "        comp_list = np.array([[0,1], [0,2], [1,2]])\n",
    "    elif len(ws_names)==4:\n",
    "        comp_list = np.array([[0,1], [0,2], [0,3], [1,2], [1,3], [2,3]])\n",
    "\n",
    "    contrast_dict = {}\n",
    "    for c1, c2 in comp_list:\n",
    "\n",
    "        contrast_str = ws_names[c1] + ' vs ' + ws_names[c2]\n",
    "        ws_contrast = post.bW.sel(within_subj=ws_names[c1]) - post.bW.sel(within_subj=ws_names[c2]) \n",
    "        ws_hdi = az.hdi(ws_contrast.values, hdi_prob=0.95)\n",
    "\n",
    "        print(contrast_str, '=', np.round(np.mean(ws_contrast.values),round_to), np.round(ws_hdi,round_to))\n",
    "\n",
    "        #Append\n",
    "        contrast_dict[contrast_str] = ws_contrast\n",
    "\n",
    "    az.plot_posterior(contrast_dict, \n",
    "                      kind=\"hist\",\n",
    "                      combine_dims={\"sample\"},\n",
    "                      bins=50,\n",
    "                      point_estimate=\"mean\", \n",
    "                      ref_val=0,\n",
    "                      round_to=round_to,\n",
    "                      hdi_prob=0.95);\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7b4a8-9499-4ee5-aba6-2b973b4e961b",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a7f5565-49c4-4975-bb55-c9c40c58c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the directory\n",
    "os.chdir('/Users/jonathanwood/Documents/GitHub/Reinforcement-learning-in-locomotion/Data')\n",
    "df = pd.read_csv('E2_sub_regress.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fd1f4-f9a3-419b-8cf4-b367ed31a06c",
   "metadata": {},
   "source": [
    "# Post-hoc explicit retention analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2436432-068a-4e4d-9a0f-93ef9b354914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>group</th>\n",
       "      <th>ret_prct</th>\n",
       "      <th>time</th>\n",
       "      <th>late_lrn</th>\n",
       "      <th>success</th>\n",
       "      <th>LSLperception</th>\n",
       "      <th>Focus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VisualFB_ER_01</td>\n",
       "      <td>te</td>\n",
       "      <td>141.044062</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.708644</td>\n",
       "      <td>69.250986</td>\n",
       "      <td>longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VisualFB_ER_02</td>\n",
       "      <td>te</td>\n",
       "      <td>96.027886</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>8.820417</td>\n",
       "      <td>73.421053</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VisualFB_ER_04</td>\n",
       "      <td>te</td>\n",
       "      <td>128.045400</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.580831</td>\n",
       "      <td>90.263158</td>\n",
       "      <td>longer</td>\n",
       "      <td>other (force), timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RewardFB_ER_05</td>\n",
       "      <td>rpe</td>\n",
       "      <td>84.762125</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>8.546459</td>\n",
       "      <td>75.526316</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RewardFB_ER_06</td>\n",
       "      <td>rpe</td>\n",
       "      <td>54.457929</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>8.835787</td>\n",
       "      <td>78.684211</td>\n",
       "      <td>not longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VisualFB_ER_07</td>\n",
       "      <td>te</td>\n",
       "      <td>106.638702</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>11.792291</td>\n",
       "      <td>63.421053</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VisualFB_ER_09</td>\n",
       "      <td>te</td>\n",
       "      <td>194.663096</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.335489</td>\n",
       "      <td>76.447368</td>\n",
       "      <td>longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RewardFB_ER_10</td>\n",
       "      <td>rpe</td>\n",
       "      <td>102.010000</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.078003</td>\n",
       "      <td>75.263158</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RewardFB_ER_11</td>\n",
       "      <td>rpe</td>\n",
       "      <td>87.752704</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>5.637589</td>\n",
       "      <td>45.131579</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>other (force)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RewardFB_ER_12</td>\n",
       "      <td>rpe</td>\n",
       "      <td>103.802982</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>8.356277</td>\n",
       "      <td>72.463768</td>\n",
       "      <td>not longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RewardFB_ER_13</td>\n",
       "      <td>rpe</td>\n",
       "      <td>39.806937</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>8.290594</td>\n",
       "      <td>69.210526</td>\n",
       "      <td>not longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VisualFB_ER_14</td>\n",
       "      <td>te</td>\n",
       "      <td>138.819831</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.860516</td>\n",
       "      <td>84.605263</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RewardFB_ER_15</td>\n",
       "      <td>rpe</td>\n",
       "      <td>114.106374</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>7.251244</td>\n",
       "      <td>50.789474</td>\n",
       "      <td>longer</td>\n",
       "      <td>step length, other (foot angle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VisualFB_ER_16</td>\n",
       "      <td>te</td>\n",
       "      <td>139.493422</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.162962</td>\n",
       "      <td>96.184211</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VisualFB_ER_17</td>\n",
       "      <td>te</td>\n",
       "      <td>96.580082</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.248819</td>\n",
       "      <td>78.552632</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RewardFB_ER_18</td>\n",
       "      <td>rpe</td>\n",
       "      <td>67.925161</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.381910</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RewardFB_ER_19</td>\n",
       "      <td>rpe</td>\n",
       "      <td>83.321735</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.971017</td>\n",
       "      <td>77.236842</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VisualFB_ER_20</td>\n",
       "      <td>te</td>\n",
       "      <td>138.260077</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.294328</td>\n",
       "      <td>93.692510</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RewardFB_ER_21</td>\n",
       "      <td>rpe</td>\n",
       "      <td>49.435416</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.626736</td>\n",
       "      <td>78.055191</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VisualFB_ER_22</td>\n",
       "      <td>te</td>\n",
       "      <td>171.431073</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>8.773725</td>\n",
       "      <td>76.842105</td>\n",
       "      <td>longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VisualFB_ER_23</td>\n",
       "      <td>te</td>\n",
       "      <td>50.509014</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.327380</td>\n",
       "      <td>73.781291</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RewardFB_ER_24</td>\n",
       "      <td>rpe</td>\n",
       "      <td>93.592773</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>7.708134</td>\n",
       "      <td>45.921053</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>other (force)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VisualFB_ER_25</td>\n",
       "      <td>te</td>\n",
       "      <td>124.478973</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>10.113253</td>\n",
       "      <td>74.734043</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RewardFB_ER_26</td>\n",
       "      <td>rpe</td>\n",
       "      <td>105.014739</td>\n",
       "      <td>Immediate</td>\n",
       "      <td>9.612261</td>\n",
       "      <td>79.868421</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VisualFB_ER_01</td>\n",
       "      <td>te</td>\n",
       "      <td>126.131092</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VisualFB_ER_02</td>\n",
       "      <td>te</td>\n",
       "      <td>33.751974</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VisualFB_ER_04</td>\n",
       "      <td>te</td>\n",
       "      <td>93.349017</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>longer</td>\n",
       "      <td>other (force), timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RewardFB_ER_05</td>\n",
       "      <td>rpe</td>\n",
       "      <td>105.225792</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RewardFB_ER_06</td>\n",
       "      <td>rpe</td>\n",
       "      <td>38.421144</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VisualFB_ER_07</td>\n",
       "      <td>te</td>\n",
       "      <td>109.648611</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VisualFB_ER_09</td>\n",
       "      <td>te</td>\n",
       "      <td>127.717776</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RewardFB_ER_10</td>\n",
       "      <td>rpe</td>\n",
       "      <td>73.755098</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RewardFB_ER_11</td>\n",
       "      <td>rpe</td>\n",
       "      <td>86.402882</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>other (force)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RewardFB_ER_12</td>\n",
       "      <td>rpe</td>\n",
       "      <td>79.324490</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RewardFB_ER_13</td>\n",
       "      <td>rpe</td>\n",
       "      <td>54.814684</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VisualFB_ER_14</td>\n",
       "      <td>te</td>\n",
       "      <td>161.960709</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RewardFB_ER_15</td>\n",
       "      <td>rpe</td>\n",
       "      <td>31.979935</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>longer</td>\n",
       "      <td>step length, other (foot angle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VisualFB_ER_16</td>\n",
       "      <td>te</td>\n",
       "      <td>123.647467</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VisualFB_ER_17</td>\n",
       "      <td>te</td>\n",
       "      <td>96.312317</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RewardFB_ER_18</td>\n",
       "      <td>rpe</td>\n",
       "      <td>29.034930</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RewardFB_ER_19</td>\n",
       "      <td>rpe</td>\n",
       "      <td>71.122723</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>VisualFB_ER_20</td>\n",
       "      <td>te</td>\n",
       "      <td>208.156350</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RewardFB_ER_21</td>\n",
       "      <td>rpe</td>\n",
       "      <td>43.320285</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>VisualFB_ER_22</td>\n",
       "      <td>te</td>\n",
       "      <td>148.228581</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>VisualFB_ER_23</td>\n",
       "      <td>te</td>\n",
       "      <td>55.217774</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RewardFB_ER_24</td>\n",
       "      <td>rpe</td>\n",
       "      <td>135.419797</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>other (force)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VisualFB_ER_25</td>\n",
       "      <td>te</td>\n",
       "      <td>102.471103</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>step length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RewardFB_ER_26</td>\n",
       "      <td>rpe</td>\n",
       "      <td>65.696295</td>\n",
       "      <td>24hr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slightly longer</td>\n",
       "      <td>timing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SID group    ret_prct       time   late_lrn    success  \\\n",
       "0   VisualFB_ER_01    te  141.044062  Immediate  10.708644  69.250986   \n",
       "1   VisualFB_ER_02    te   96.027886  Immediate   8.820417  73.421053   \n",
       "2   VisualFB_ER_04    te  128.045400  Immediate   9.580831  90.263158   \n",
       "3   RewardFB_ER_05   rpe   84.762125  Immediate   8.546459  75.526316   \n",
       "4   RewardFB_ER_06   rpe   54.457929  Immediate   8.835787  78.684211   \n",
       "5   VisualFB_ER_07    te  106.638702  Immediate  11.792291  63.421053   \n",
       "6   VisualFB_ER_09    te  194.663096  Immediate   9.335489  76.447368   \n",
       "7   RewardFB_ER_10   rpe  102.010000  Immediate   9.078003  75.263158   \n",
       "8   RewardFB_ER_11   rpe   87.752704  Immediate   5.637589  45.131579   \n",
       "9   RewardFB_ER_12   rpe  103.802982  Immediate   8.356277  72.463768   \n",
       "10  RewardFB_ER_13   rpe   39.806937  Immediate   8.290594  69.210526   \n",
       "11  VisualFB_ER_14    te  138.819831  Immediate  10.860516  84.605263   \n",
       "12  RewardFB_ER_15   rpe  114.106374  Immediate   7.251244  50.789474   \n",
       "13  VisualFB_ER_16    te  139.493422  Immediate  10.162962  96.184211   \n",
       "14  VisualFB_ER_17    te   96.580082  Immediate   9.248819  78.552632   \n",
       "15  RewardFB_ER_18   rpe   67.925161  Immediate  10.381910  73.333333   \n",
       "16  RewardFB_ER_19   rpe   83.321735  Immediate   9.971017  77.236842   \n",
       "17  VisualFB_ER_20    te  138.260077  Immediate   9.294328  93.692510   \n",
       "18  RewardFB_ER_21   rpe   49.435416  Immediate  10.626736  78.055191   \n",
       "19  VisualFB_ER_22    te  171.431073  Immediate   8.773725  76.842105   \n",
       "20  VisualFB_ER_23    te   50.509014  Immediate  10.327380  73.781291   \n",
       "21  RewardFB_ER_24   rpe   93.592773  Immediate   7.708134  45.921053   \n",
       "22  VisualFB_ER_25    te  124.478973  Immediate  10.113253  74.734043   \n",
       "23  RewardFB_ER_26   rpe  105.014739  Immediate   9.612261  79.868421   \n",
       "24  VisualFB_ER_01    te  126.131092       24hr        NaN        NaN   \n",
       "25  VisualFB_ER_02    te   33.751974       24hr        NaN        NaN   \n",
       "26  VisualFB_ER_04    te   93.349017       24hr        NaN        NaN   \n",
       "27  RewardFB_ER_05   rpe  105.225792       24hr        NaN        NaN   \n",
       "28  RewardFB_ER_06   rpe   38.421144       24hr        NaN        NaN   \n",
       "29  VisualFB_ER_07    te  109.648611       24hr        NaN        NaN   \n",
       "30  VisualFB_ER_09    te  127.717776       24hr        NaN        NaN   \n",
       "31  RewardFB_ER_10   rpe   73.755098       24hr        NaN        NaN   \n",
       "32  RewardFB_ER_11   rpe   86.402882       24hr        NaN        NaN   \n",
       "33  RewardFB_ER_12   rpe   79.324490       24hr        NaN        NaN   \n",
       "34  RewardFB_ER_13   rpe   54.814684       24hr        NaN        NaN   \n",
       "35  VisualFB_ER_14    te  161.960709       24hr        NaN        NaN   \n",
       "36  RewardFB_ER_15   rpe   31.979935       24hr        NaN        NaN   \n",
       "37  VisualFB_ER_16    te  123.647467       24hr        NaN        NaN   \n",
       "38  VisualFB_ER_17    te   96.312317       24hr        NaN        NaN   \n",
       "39  RewardFB_ER_18   rpe   29.034930       24hr        NaN        NaN   \n",
       "40  RewardFB_ER_19   rpe   71.122723       24hr        NaN        NaN   \n",
       "41  VisualFB_ER_20    te  208.156350       24hr        NaN        NaN   \n",
       "42  RewardFB_ER_21   rpe   43.320285       24hr        NaN        NaN   \n",
       "43  VisualFB_ER_22    te  148.228581       24hr        NaN        NaN   \n",
       "44  VisualFB_ER_23    te   55.217774       24hr        NaN        NaN   \n",
       "45  RewardFB_ER_24   rpe  135.419797       24hr        NaN        NaN   \n",
       "46  VisualFB_ER_25    te  102.471103       24hr        NaN        NaN   \n",
       "47  RewardFB_ER_26   rpe   65.696295       24hr        NaN        NaN   \n",
       "\n",
       "      LSLperception                            Focus  \n",
       "0            longer                           timing  \n",
       "1   slightly longer                           timing  \n",
       "2            longer            other (force), timing  \n",
       "3   slightly longer                      step length  \n",
       "4        not longer                      step length  \n",
       "5   slightly longer                      step length  \n",
       "6            longer                      step length  \n",
       "7   slightly longer                           timing  \n",
       "8   slightly longer                    other (force)  \n",
       "9        not longer                      step length  \n",
       "10       not longer                      step length  \n",
       "11  slightly longer                      step length  \n",
       "12           longer  step length, other (foot angle)  \n",
       "13  slightly longer                      step length  \n",
       "14  slightly longer                           timing  \n",
       "15  slightly longer                      step length  \n",
       "16  slightly longer                           timing  \n",
       "17  slightly longer                      step length  \n",
       "18  slightly longer                      step length  \n",
       "19           longer                      step length  \n",
       "20  slightly longer                      step length  \n",
       "21  slightly longer                    other (force)  \n",
       "22  slightly longer                      step length  \n",
       "23  slightly longer                           timing  \n",
       "24           longer                           timing  \n",
       "25  slightly longer                           timing  \n",
       "26           longer            other (force), timing  \n",
       "27  slightly longer                      step length  \n",
       "28       not longer                      step length  \n",
       "29  slightly longer                      step length  \n",
       "30           longer                      step length  \n",
       "31  slightly longer                           timing  \n",
       "32  slightly longer                    other (force)  \n",
       "33       not longer                      step length  \n",
       "34       not longer                      step length  \n",
       "35  slightly longer                      step length  \n",
       "36           longer  step length, other (foot angle)  \n",
       "37  slightly longer                      step length  \n",
       "38  slightly longer                           timing  \n",
       "39  slightly longer                      step length  \n",
       "40  slightly longer                           timing  \n",
       "41  slightly longer                      step length  \n",
       "42  slightly longer                      step length  \n",
       "43           longer                      step length  \n",
       "44  slightly longer                      step length  \n",
       "45  slightly longer                    other (force)  \n",
       "46  slightly longer                      step length  \n",
       "47  slightly longer                           timing  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2506df-7214-44e9-b34e-f9a3e6fee030",
   "metadata": {},
   "source": [
    "## Success and Immediate retention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4862e661-0af6-4afe-8179-59469c131185",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grp, _, _ = bst.parse_categorical(df.group[df.time=='Immediate'])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Define priors\n",
    "    beta0 = pm.Normal(\"beta0\", mu=100, sigma=100)\n",
    "    beta_success = pm.Normal(\"beta_success\", mu=0, sigma=5)\n",
    "    beta_group = pm.Normal(\"beta_group\", mu=0, sigma=5, shape=2)\n",
    "\n",
    "    nu_minus_one = pm.Exponential(\"nu_minus_one\", 1 / 29)\n",
    "    nu = pm.Exponential(\"nu\", nu_minus_one + 1)\n",
    "    nu_log10 = pm.Deterministic(\"nu_log10\", np.log10(nu))\n",
    "\n",
    "    mu = beta0 + beta_group[x_grp] + beta_success*df.success[df.time=='Immediate']\n",
    "    sigma = pm.Uniform(\"sigma\", 10**-10, 1000)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.StudentT(\"likelihood\", nu=nu, mu=mu, lam=1 / sigma**2, observed=df.ret_prct[df.time=='Immediate'])\n",
    "    \n",
    "    # Sample the posterior\n",
    "    # idata = pm.sample(draws=1000, tune=2000, target_accept=0.95, random_seed=seed_num, chains=4, cores=8, init='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10869d57-3218-4242-952f-27f9d2642b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model:\n\u001b[0;32m----> 2\u001b[0m     trace_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madapt_diag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/sampling.py:535\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, initvals, trace, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, keep_warning_stat, idata_kwargs, mp_ctx, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    534\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43massign_step_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEP_METHODS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    538\u001b[0m     step \u001b[38;5;241m=\u001b[39m CompoundStep(step)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/sampling.py:229\u001b[0m, in \u001b[0;36massign_step_methods\u001b[0;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    222\u001b[0m             methods,\n\u001b[1;32m    223\u001b[0m             key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m method, var\u001b[38;5;241m=\u001b[39mrv_var, has_gradient\u001b[38;5;241m=\u001b[39mhas_gradient: method\u001b[38;5;241m.\u001b[39m_competence(\n\u001b[1;32m    224\u001b[0m                 var, has_gradient\n\u001b[1;32m    225\u001b[0m             ),\n\u001b[1;32m    226\u001b[0m         )\n\u001b[1;32m    227\u001b[0m         selected_steps[selected]\u001b[38;5;241m.\u001b[39mappend(var)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_steppers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/sampling.py:147\u001b[0m, in \u001b[0;36minstantiate_steppers\u001b[0;34m(model, steps, selected_steps, step_kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         args \u001b[38;5;241m=\u001b[39m step_kwargs\u001b[38;5;241m.\u001b[39mget(step_class\u001b[38;5;241m.\u001b[39mname, {})\n\u001b[1;32m    146\u001b[0m         used_keys\u001b[38;5;241m.\u001b[39madd(step_class\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 147\u001b[0m         step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         steps\u001b[38;5;241m.\u001b[39mappend(step)\n\u001b[1;32m    150\u001b[0m unused_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(step_kwargs)\u001b[38;5;241m.\u001b[39mdifference(used_keys)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/step_methods/hmc/nuts.py:180\u001b[0m, in \u001b[0;36mNUTS.__init__\u001b[0;34m(self, vars, max_treedepth, early_max_treedepth, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, early_max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up the No-U-Turn sampler.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    `pm.sample` to the desired number of tuning steps.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_treedepth \u001b[38;5;241m=\u001b[39m max_treedepth\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_max_treedepth \u001b[38;5;241m=\u001b[39m early_max_treedepth\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/step_methods/hmc/base_hmc.py:96\u001b[0m, in \u001b[0;36mBaseHMC.__init__\u001b[0;34m(self, vars, scaling, step_scale, is_cov, model, blocked, potential, dtype, Emax, target_accept, gamma, k, t0, adapt_step_size, step_rand, **aesara_kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mrvs_to_values\u001b[38;5;241m.\u001b[39mget(var, var) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m]\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maesara_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_step_size \u001b[38;5;241m=\u001b[39m adapt_step_size\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEmax \u001b[38;5;241m=\u001b[39m Emax\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/step_methods/arraystep.py:276\u001b[0m, in \u001b[0;36mGradientSharedStep.__init__\u001b[0;34m(self, vars, model, blocked, dtype, logp_dlogp_func, **aesara_kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m model \u001b[38;5;241m=\u001b[39m modelcontext(model)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logp_dlogp_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogp_dlogp_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maesara_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     func \u001b[38;5;241m=\u001b[39m logp_dlogp_func\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/model.py:629\u001b[0m, in \u001b[0;36mModel.logp_dlogp_function\u001b[0;34m(self, grad_vars, tempered, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m     costs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogp()]\n\u001b[1;32m    628\u001b[0m input_vars \u001b[38;5;241m=\u001b[39m {i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m graph_inputs(costs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, Constant)}\n\u001b[0;32m--> 629\u001b[0m ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_point\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m extra_vars_and_values \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    631\u001b[0m     var: ip[var\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_vars\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m input_vars \u001b[38;5;129;01mand\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m grad_vars\n\u001b[1;32m    634\u001b[0m }\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ValueGradFunction(costs, grad_vars, extra_vars_and_values, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/model.py:1272\u001b[0m, in \u001b[0;36mModel.initial_point\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitial_point\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes the initial point of the model.\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m \n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;124;03m        Maps names of transformed variables to numeric initial values in the transformed space.\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[43mmake_initial_point_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_transformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Point(fn(seed), model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/initial_point.py:171\u001b[0m, in \u001b[0;36mmake_initial_point_fn\u001b[0;34m(model, overrides, jitter_rvs, default_strategy, return_transformed)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Replace original rng shared variables so that we don't mess with them\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# when calling the final seeded function\u001b[39;00m\n\u001b[1;32m    170\u001b[0m initial_values \u001b[38;5;241m=\u001b[39m replace_rng_nodes(initial_values)\n\u001b[0;32m--> 171\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_pymc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maesara\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFAST_COMPILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m varnames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfree_RVs:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/aesaraf.py:970\u001b[0m, in \u001b[0;36mcompile_pymc\u001b[0;34m(inputs, outputs, random_seed, mode, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m opt_qry \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mprovided_optimizer\u001b[38;5;241m.\u001b[39mincluding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_make_inplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_parameter_opt)\n\u001b[1;32m    969\u001b[0m mode \u001b[38;5;241m=\u001b[39m Mode(linker\u001b[38;5;241m=\u001b[39mmode\u001b[38;5;241m.\u001b[39mlinker, optimizer\u001b[38;5;241m=\u001b[39mopt_qry)\n\u001b[0;32m--> 970\u001b[0m aesara_function \u001b[38;5;241m=\u001b[39m \u001b[43maesara\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrng_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aesara_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/compile/function/__init__.py:317\u001b[0m, in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    311\u001b[0m     fn \u001b[38;5;241m=\u001b[39m orig_function(\n\u001b[1;32m    312\u001b[0m         inputs, outputs, mode\u001b[38;5;241m=\u001b[39mmode, accept_inplace\u001b[38;5;241m=\u001b[39maccept_inplace, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# note: pfunc will also call orig_function -- orig_function is\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m#      a choke point that all compilation must pass through\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[43mpfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgivens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgivens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_default_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_default_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrebuild_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrebuild_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_input_downcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_input_downcast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_unused_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_unused_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/compile/function/pfunc.py:371\u001b[0m, in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys, fgraph)\u001b[0m\n\u001b[1;32m    357\u001b[0m     profile \u001b[38;5;241m=\u001b[39m ProfileStats(message\u001b[38;5;241m=\u001b[39mprofile)\n\u001b[1;32m    359\u001b[0m inputs, cloned_outputs \u001b[38;5;241m=\u001b[39m construct_pfunc_ins_and_outs(\n\u001b[1;32m    360\u001b[0m     params,\n\u001b[1;32m    361\u001b[0m     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     fgraph\u001b[38;5;241m=\u001b[39mfgraph,\n\u001b[1;32m    369\u001b[0m )\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43morig_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_unused_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_unused_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/compile/function/types.py:1759\u001b[0m, in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys, fgraph)\u001b[0m\n\u001b[1;32m   1747\u001b[0m     m \u001b[38;5;241m=\u001b[39m Maker(\n\u001b[1;32m   1748\u001b[0m         inputs,\n\u001b[1;32m   1749\u001b[0m         outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1756\u001b[0m         fgraph\u001b[38;5;241m=\u001b[39mfgraph,\n\u001b[1;32m   1757\u001b[0m     )\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mchange_flags(compute_test_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1759\u001b[0m         fn \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1761\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/compile/function/types.py:1652\u001b[0m, in \u001b[0;36mFunctionMaker.create\u001b[0;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[1;32m   1649\u001b[0m start_import_time \u001b[38;5;241m=\u001b[39m aesara\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39mc\u001b[38;5;241m.\u001b[39mcmodule\u001b[38;5;241m.\u001b[39mimport_time\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mchange_flags(traceback__limit\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtraceback__compile_limit):\n\u001b[0;32m-> 1652\u001b[0m     _fn, _i, _o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_thunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_storage_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_map\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1656\u001b[0m end_linker \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1658\u001b[0m linker_time \u001b[38;5;241m=\u001b[39m end_linker \u001b[38;5;241m-\u001b[39m start_linker\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/link/basic.py:254\u001b[0m, in \u001b[0;36mLocalLinker.make_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_thunk\u001b[39m(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    249\u001b[0m     input_storage: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputStorageType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasicThunkType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputStorageType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputStorageType\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/link/vm.py:1300\u001b[0m, in \u001b[0;36mVMLinker.make_all\u001b[0;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     post_thunk_clear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1300\u001b[0m vm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_vm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_thunk_clear\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdated_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m vm\u001b[38;5;241m.\u001b[39mstorage_map \u001b[38;5;241m=\u001b[39m storage_map\n\u001b[1;32m   1313\u001b[0m vm\u001b[38;5;241m.\u001b[39mcompute_map \u001b[38;5;241m=\u001b[39m compute_map\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/link/vm.py:1021\u001b[0m, in \u001b[0;36mVMLinker.make_vm\u001b[0;34m(self, nodes, thunks, input_storage, output_storage, storage_map, post_thunk_clear, computed, compute_map, updated_vars)\u001b[0m\n\u001b[1;32m   1018\u001b[0m pre_call_clear \u001b[38;5;241m=\u001b[39m [storage_map[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_recycling]\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maesara\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CVM\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (MissingGXX, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[1;32m   1023\u001b[0m     CVM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/link/c/cvm.py:13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcxx:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingGXX(\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlazylinker will not be imported if aesara.config.cxx is not set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maesara\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazylinker_c\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLazyLinker\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCVM\u001b[39;00m(CLazyLinker, VM):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fgraph, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/aesara/link/c/lazylinker_c.py:170\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlazylinker_ext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazylinker_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLazyLinker, get_version  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlazylinker_ext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazylinker_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m force_compile \u001b[38;5;129;01mor\u001b[39;00m (version \u001b[38;5;241m==\u001b[39m get_version())  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace_1 = pm.sample(draws=1000, tune=2000, target_accept=0.95, random_seed=1, chains=4, cores=8, init='adapt_diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc55cc-a8b9-416a-a4be-3230a905edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cbbea-5365-4f2c-bd20-70ee33898e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot posterior values\n",
    "posterior = az.extract(idata.posterior)\n",
    "\n",
    "az.plot_posterior(posterior,\n",
    "                  combine_dims={\"sample\"},\n",
    "                  var_names=[\"beta0\", \"beta_group\", \"beta_success\"],\n",
    "                  kind=\"hist\",\n",
    "                  bins=50,\n",
    "                  hdi_prob=0.95,\n",
    "                  point_estimate=\"mean\",\n",
    "                  ref_val=0,\n",
    "                  round_to=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa46a7-567b-4697-9e6b-5ff850fc40d8",
   "metadata": {},
   "source": [
    "## Success and 24 hour retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba9eb1a2-94e3-4b24-8272-9e8b1e680550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "ename": "SamplingError",
     "evalue": "Initial evaluation of model at starting point failed!\nStarting values:\n{'beta0': array(99.38037664), 'beta_success': array(0.3853925), 'beta_group': array([ 0.92329599, -0.12768987]), 'nu_minus_one_log__': array(4.15407838), 'nu_log__': array(-4.44669934), 'sigma_interval__': array(-0.07109853)}\n\nInitial evaluation results:\n{'beta0': -5.52, 'beta_success': -2.53, 'beta_group': -5.07, 'nu_minus_one': -1.41, 'nu': -1.04, 'sigma': -1.39, 'likelihood': nan}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mStudentT(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m, nu\u001b[38;5;241m=\u001b[39mnu, mu\u001b[38;5;241m=\u001b[39mmu, lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, observed\u001b[38;5;241m=\u001b[39mdf2_sub\u001b[38;5;241m.\u001b[39mret_prct[df2_sub\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m24hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Sample the posterior\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/sampling.py:569\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, initvals, trace, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, keep_warning_stat, idata_kwargs, mp_ctx, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# One final check that shapes and logps at the starting points are okay.\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ip \u001b[38;5;129;01min\u001b[39;00m initial_points:\n\u001b[0;32m--> 569\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_start_vals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     _check_start_shape(model, ip)\n\u001b[1;32m    572\u001b[0m sample_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdraws\u001b[39m\u001b[38;5;124m\"\u001b[39m: draws,\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m: step,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscard_tuned_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: discard_tuned_samples,\n\u001b[1;32m    584\u001b[0m }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bayes_toolbox/lib/python3.11/site-packages/pymc/model.py:1729\u001b[0m, in \u001b[0;36mModel.check_start_vals\u001b[0;34m(self, start)\u001b[0m\n\u001b[1;32m   1726\u001b[0m initial_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_logps(point\u001b[38;5;241m=\u001b[39melem)\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m initial_eval\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SamplingError(\n\u001b[1;32m   1730\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial evaluation of model at starting point failed!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1731\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00melem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial evaluation results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minitial_eval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1733\u001b[0m     )\n",
      "\u001b[0;31mSamplingError\u001b[0m: Initial evaluation of model at starting point failed!\nStarting values:\n{'beta0': array(99.38037664), 'beta_success': array(0.3853925), 'beta_group': array([ 0.92329599, -0.12768987]), 'nu_minus_one_log__': array(4.15407838), 'nu_log__': array(-4.44669934), 'sigma_interval__': array(-0.07109853)}\n\nInitial evaluation results:\n{'beta0': -5.52, 'beta_success': -2.53, 'beta_group': -5.07, 'nu_minus_one': -1.41, 'nu': -1.04, 'sigma': -1.39, 'likelihood': nan}"
     ]
    }
   ],
   "source": [
    "x_grp, _, _ = bst.parse_categorical(df2_sub.group[df2_sub.time=='24hr'])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Define priors\n",
    "    beta0 = pm.Normal(\"beta0\", mu=100, sigma=100)\n",
    "    beta_success = pm.Normal(\"beta_success\", mu=0, sigma=5)\n",
    "    beta_group = pm.Normal(\"beta_group\", mu=0, sigma=5, shape=2)\n",
    "\n",
    "    nu_minus_one = pm.Exponential(\"nu_minus_one\", 1 / 29)\n",
    "    nu = pm.Exponential(\"nu\", nu_minus_one + 1)\n",
    "    nu_log10 = pm.Deterministic(\"nu_log10\", np.log10(nu))\n",
    "\n",
    "    mu = beta0 + beta_group[x_grp] + beta_success*df2_sub.success[df2_sub.time=='24hr']\n",
    "    sigma = pm.Uniform(\"sigma\", 10**-10, 1000)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.StudentT(\n",
    "        \"likelihood\", nu=nu, mu=mu, lam=1 / sigma**2, observed=df2_sub.ret_prct[df2_sub.time=='24hr']\n",
    "    )\n",
    "    \n",
    "    # Sample the posterior\n",
    "    idata = pm.sample(draws=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7db15b-9454-435b-971f-c39456a81769",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78066f7f-fdce-4c42-9d2d-9e9a3624e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot posterior values\n",
    "posterior = az.extract(idata.posterior)\n",
    "\n",
    "az.plot_posterior(posterior,\n",
    "                  combine_dims={\"sample\"},\n",
    "                  var_names=[\"beta0\", \"beta_group\", \"beta_success\"],\n",
    "                  kind=\"hist\",\n",
    "                  bins=50,\n",
    "                  hdi_prob=0.95,\n",
    "                  point_estimate=\"mean\",\n",
    "                  ref_val=0,\n",
    "                  round_to=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113dc466-3820-4a9b-8d13-bcbd4e4676dc",
   "metadata": {},
   "source": [
    "## Step length perception analysis \n",
    "\n",
    "First, we need to determine if there are differences between the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fba6843e-f68c-43e4-a091-809836bcb142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              longer\n",
       "1     slightly longer\n",
       "2              longer\n",
       "3     slightly longer\n",
       "4          not longer\n",
       "5     slightly longer\n",
       "6              longer\n",
       "7     slightly longer\n",
       "8     slightly longer\n",
       "9          not longer\n",
       "10         not longer\n",
       "11    slightly longer\n",
       "12             longer\n",
       "13    slightly longer\n",
       "14    slightly longer\n",
       "15    slightly longer\n",
       "16    slightly longer\n",
       "17    slightly longer\n",
       "18    slightly longer\n",
       "19             longer\n",
       "20    slightly longer\n",
       "21    slightly longer\n",
       "22    slightly longer\n",
       "23    slightly longer\n",
       "Name: LSLperception, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_sub.LSLperception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3d33d08-2760-4939-ac05-8d9c2d64ba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longer', 'not longer', 'slightly longer'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_percept, levels, n_levels = bst.parse_categorical(df2_sub.LSLperception)\n",
    "x_percept\n",
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d09c51-d5cf-4a6a-aa5e-d1aa8c536721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mparse_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A function for extracting information from a grouping variable.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    If the input arg is not already a category-type variable, converts\u001b[0m\n",
       "\u001b[0;34m    it to one. Then, extracts the codes, unique levels, and number of\u001b[0m\n",
       "\u001b[0;34m    levels from the variable.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        x (categorical): The categorical type variable to parse.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns:\u001b[0m\n",
       "\u001b[0;34m        The codes, unique levels, and number of levels from the input variable.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# First, check to see if passed variable is of type \"category\".\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcategorical_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mcategorical_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/GitHub/bayesian-statistics-toolbox/bayes_toolbox/glm.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bst.parse_categorical??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes_toolbox",
   "language": "python",
   "name": "bayes_toolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
